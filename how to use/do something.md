

这节我们介绍爬虫能用来干什么.如今每天互联网上的流量足足有10亿GB左右，不可能毫无选择的全部爬取下来，这是要根据我们自己的需求来有选择的爬取相对应的数据.那爬虫可以用来干什么呢？我们根据实际需要将爬虫的目标分为三类.
 第一类是通过搜索引擎的网络爬虫来充实搜索引擎的索引列表.这部分需求所需要的数据是各种网页的地址，标题，主题字等等.这方面比较知名的有google爬虫，baidu爬虫，Yahoo爬虫等等。可以大致分为 批量型爬虫（Batch Crawler），增量型爬虫（Incremental Crawler），垂直型爬虫(Focused Crawter）.
 第二类建立自己的数据仓库，然后用各种机器学习模型来得出一些寻常无法得出的预测和分析.这部分需求所需要的数据是我们研究的这个结论相对应的各种关联数据。用一个经典例子来讲的话，有一篇著名的论文是用来讨论网络情感对股票的影响.如果你也想如此这般的话，那么你就得去持续不断的抓取社交网络数据以及当时的股票数据.
 第三类为各种论文以及文章提供有力的数据支撑.我们一般在报告中看到的有关于各行各业的数据分析图，那都是通过抓取特定行业的专业数据，然后用各种数据分析也好，自己使用第三方可视化js库也好，最终得出的这些表图.同样用例子来说明，如果你想要证明X才是一年中平均温度最高的，那么首先你的搜集到所有城市一年中的平均气温，然后通过可视化图片来直观的展示出来.
现在的你，是不是应该想想自己想要做的爬虫是上面中的哪一类呢？