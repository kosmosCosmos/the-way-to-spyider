本章节将开始讲述那些厂商为何确保自己的利益是怎么样进行反爬的.实话说，与对方的反爬措施做斗争可以称得上开发过程中为数不多的趣味了，同样也可以说是一种折磨了.

  
你会见到各种奇妙无比，匪夷所思，令人拍案叫绝的反爬手段。同时你还得绞尽脑汁的去绕过这些.在前面的章节中，我们提到爬虫是我们获取互联网信息的一种重要手段,那么有矛必有盾.一方面是千方百计想要爬取数据的你，另一方面是誓死捍卫自己数据的守护者.一场较量再所难免.......

  
回到正题，目前市面上的反爬措施很多，也有很多奇妙的，奇特的，恶毒的都有.我们从本质出发，目前市面的大概可以分成这么几个大类.

* 根据访问日志，流量，爬取行为以及各种相关算法来判定该行为是不是爬虫所为，从而触发黑名单或者蜜罐系统。例如最为经典的封禁IP和封禁账号.这一类用途最广，防范水平要看其判断策略写的如何.
* 利用ajax技术，通过js脚本实现动态渲染的后台传输类.比如说通过JSON实现前端与后端通信.这种有人也许会说这也能算反爬措施?但这种至少你读取网页源码时是得不到数据的，只能通过抓包等方式解决.这一类基本在需要交互的网站中运用的许多.抓包一般可以用burpsuite,fiddle这类软件进行抓包.
* 通过浏览器环境，在本地运算js，最终得到所需的数据的本地js类.因为现在浏览器都有内核从而实现了自带javascript环境.在本地环境中即时运算从而得到数据.从我的经验来看，这一类是很难对付的，而且即使有解决方案，但效率很低而且爬虫程序不容易写.
* 各种找不到形容词，只能用奇思妙想来形容的反爬类.一些通过图像混淆，页面无限循环，给爬虫投毒等等行为可以归入此类.

下面的几个小节，我们就会从上面的几个点出发，带你深入的了解一下这个爬虫中最有趣的环境以及这个最能折磨人的环节.

